{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd070424dbd69a178df61989ee9276069a7c1e5e9a512b62acb474308febe74a347",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f5b44d34071054b8520a0835eb319b5292b54794f9be8f4b3e974d933d81d2b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Aufgabe 2\n",
    "## a\n",
    "Lesen Sie die Trainingsdaten ein und teilen Sie sie in ein Validierungsdatenset (20%) und in ein eigentliches Trainigsdatenset (80%) auf. Finden Sie auf dem Validierungsdatensatz eine Regel für das Überleben alleine aufgrund der Klasse des Tickets (Pclass). Wenden Sie diese Regel auf die Validierungsdaten an. Wie gut ist die Genauigkeit (Anteil der korrekten Klassifikationen) auf den Validierungsdaten?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "x = data[['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
    "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']]\n",
    "y = data[\"Survived\"]\n",
    "data.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 64,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 64
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "pclass_train_x = x_train[\"Pclass\"].to_numpy()\n",
    "pclass_train_y = y_train.to_numpy()\n",
    "pclass_val_x = x_val[\"Pclass\"].to_numpy()\n",
    "pclass_val_y = y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def predict(x):\n",
    "    random.seed(42)\n",
    "    predicted = np.zeros(len(x),dtype=int)\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == 1:\n",
    "            predicted[i] = 1\n",
    "        elif x[i] == 2:\n",
    "            r = random.random()\n",
    "            if r > 0.5:\n",
    "                predicted[i] = 0\n",
    "            else:\n",
    "                predicted[i] = 1\n",
    "        else:\n",
    "            predicted[i] = 0\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6815642458100558"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "predicted = predict(pclass_val_x)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(pclass_val_y,predicted)"
   ]
  },
  {
   "source": [
    "# b\n",
    "Wenden Sie die Regel aus a) auf die Testdaten an und laden Sie Ihre Lösung hoch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "text_x = test_data[\"Pclass\"].to_numpy()\n",
    "predicted = predict(text_x)"
   ]
  },
  {
   "source": [
    "# c\n",
    "Trainieren Sie eine logistische Regression mit den Variablen 'Pclass'. Verwenden Sie die Klasse sklearn.linear_model.LogisticRegression. Berechnen Sie die Accuracy auf dem Validierungsset.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/onder/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7039106145251397"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "res = model.fit(pclass_train_x.reshape(len(pclass_train_x),1),y_train)\n",
    "p = model.predict(pclass_val_x.reshape(len(pclass_val_x),1))\n",
    "accuracy_score(p,pclass_val_y)"
   ]
  },
  {
   "source": [
    "# d\n",
    "Verwenden Sie nun weitere Features. Die Variable Age enthält Missing values, die Sie durch folgenden code ersetzen können (was passiert da?)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/onder/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6287: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "final_train_x = x_train[[\"Pclass\",\"Sex\",\"Age\"]]\n",
    "final_train_y = y_train\n",
    "final_train_x[\"Age\"].fillna(final_train_x[\"Age\"].median(skipna=True),inplace=True)\n",
    "\n",
    "final_val_x = x_val[[\"Pclass\",\"Sex\",\"Age\"]]\n",
    "final_val_x[\"Age\"].fillna(final_val_x[\"Age\"].median(skipna=True),inplace=True)\n",
    "final_train_x = pd.concat([final_train_x.drop('Sex', axis=1), pd.get_dummies(final_train_x['Sex'])], axis=1)\n",
    "final_train_x = pd.concat([final_train_x.drop('Pclass', axis=1), pd.get_dummies(final_train_x['Pclass'])], axis=1)\n",
    "final_val_x = pd.concat([final_val_x.drop('Sex', axis=1), pd.get_dummies(final_val_x['Sex'])], axis=1)\n",
    "final_val_x = pd.concat([final_val_x.drop('Pclass', axis=1), pd.get_dummies(final_val_x['Pclass'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/onder/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "final_train_x = final_train_x.to_numpy()\n",
    "final_val_x = final_val_x.to_numpy()\n",
    "\n",
    "model = LogisticRegression()\n",
    "res = model.fit(final_train_x,y_train)\n",
    "p = model.predict(final_val_x)\n",
    "accuracy_score(p,pclass_val_y)"
   ]
  },
  {
   "source": [
    "# e\n",
    "Weitere Klassifikatoren. Neben der logistischen Regression, gibt es weitere Klassifikatoren. Der Random-Forest ist ein recht stabiler Klassifikator, was wäre die Performance von diesem Klassifikator."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/onder/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7150837988826816"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "res = model.fit(final_train_x,y_train)\n",
    "p = model.predict(final_val_x)\n",
    "accuracy_score(p,pclass_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6983240223463687"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "res = model.fit(final_train_x,y_train)\n",
    "p = model.predict(final_val_x)\n",
    "accuracy_score(p,pclass_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7374301675977654"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "res = model.fit(final_train_x,y_train)\n",
    "p = model.predict(final_val_x)\n",
    "accuracy_score(p,pclass_val_y)"
   ]
  },
  {
   "source": [
    "## Aufgabe 3\n",
    "Mit den gleichen Daten, wie in der Aufgabe 2 d. Erstellen Sie ein fully connected neural network und fitten es an die Ttrainingsdaten. Verwenden Sie mindestens einen hidden Layer. Plotten Sie den Verlauf der Loss Kurve für die Trainings- und Validierungsdaten. Optional: Laden Sie Ihre beste Lösung auf Kaggle hoch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7374301675977654"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(20,10,5,3,2),max_iter=3000)\n",
    "res = model.fit(final_train_x,y_train)\n",
    "p = model.predict(final_val_x)\n",
    "accuracy_score(p,y_val)"
   ]
  }
 ]
}